# -*- coding: utf-8 -*-
"""Flask_app.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1l2UH3A8LEGXVP1iYhaf8OWAmPuZwkK5V
"""





from flask import Flask, render_template, request, jsonify
from llm_chatbot_code import query_model  # LLM query model

# Initialize Flask App
app = Flask(__name__)

@app.route('/')
def index():
    """Render the main query interface."""
    return render_template('index.html')


@app.route('/query', methods=['POST'])
def query():
    """Process the user query and return a structured response."""
    user_query = request.json.get('query')

    # Generate the response from the model
    response = query_model(user_query)

    # Mock response for demonstration (Replace this with the actual model's response structure)
    example_response = {
        "entered_query": user_query,
        "intent_steps": [
            "Extract query intent.",
            "Check dataset for matching records.",
            "Filter relevant promotions based on criteria."
        ],
        "query_type": "Predictive Analysis",
        "filtered_dataset": [
            {"Item": "Item_177", "Promotion": "Discount", "ROI": "15%"},
            {"Item": "Item_189", "Promotion": "BOGO", "ROI": "18%"}
        ]
    }

    return jsonify(example_response)


if __name__ == "__main__":
    app.run(debug=True, port=5000)